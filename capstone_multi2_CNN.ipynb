{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2识别数字序列的卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (33152, 40, 40)\n",
      "Training labels shape:  (33152, 5)\n",
      "Validing dataset shape:  (250, 40, 40)\n",
      "Validing labels shape:  (250, 5)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'svhn_multi_train.pickle'\n",
    "VALID_SIZE = int(500 / 2)\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    train_dataset = dataset['dataset'][VALID_SIZE:]\n",
    "    train_labels = dataset['labels'][VALID_SIZE:, 1:6]\n",
    "    valid_dataset = dataset['dataset'][:VALID_SIZE]\n",
    "    valid_labels = dataset['labels'][:VALID_SIZE, 1:6]\n",
    "    \n",
    "print('Training dataset shape: ', train_dataset.shape)\n",
    "print('Training labels shape: ', train_labels.shape)\n",
    "print('Validing dataset shape: ', valid_dataset.shape)\n",
    "print('Validing labels shape: ', valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (202902, 40, 40)\n",
      "Training labels shape:  (202902, 5)\n",
      "Validing dataset shape:  (500, 40, 40)\n",
      "Validing labels shape:  (500, 5)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'svhn_multi_extra.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    train_dataset = np.vstack((train_dataset, dataset['dataset'][VALID_SIZE:170000]))\n",
    "    train_labels = np.vstack((train_labels, dataset['labels'][VALID_SIZE:170000, 1:6]))\n",
    "    valid_dataset = np.vstack((valid_dataset, dataset['dataset'][:VALID_SIZE]))\n",
    "    valid_labels = np.vstack((valid_labels, dataset['labels'][:VALID_SIZE, 1:6]))\n",
    "    \n",
    "print('Training dataset shape: ', train_dataset.shape)\n",
    "print('Training labels shape: ', train_labels.shape)\n",
    "print('Validing dataset shape: ', valid_dataset.shape)\n",
    "print('Validing labels shape: ', valid_labels.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  6, 10, 10, 10],\n",
       "       [ 3,  7,  0, 10, 10],\n",
       "       [ 1,  9, 10, 10, 10],\n",
       "       [ 3,  5, 10, 10, 10],\n",
       "       [ 9,  3, 10, 10, 10],\n",
       "       [ 2,  8, 10, 10, 10],\n",
       "       [ 1,  1, 10, 10, 10],\n",
       "       [ 5,  6, 10, 10, 10],\n",
       "       [ 5, 10, 10, 10, 10],\n",
       "       [ 3,  6, 10, 10, 10]], dtype=int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (202902, 40, 40, 1) (202902, 5)\n",
      "Validation set (500, 40, 40, 1) (500, 5)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 40\n",
    "NUM_DIGITS = 5\n",
    "NUM_LABELS = 11 # 0-9 + 10==doesn't exist\n",
    "NUM_CHANNELS = 1 # grayscale\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)).astype(np.float32)\n",
    "    #labels = (np.array([10,1,2,3,4,5,6,7,8,9]) == labels).astype(np.float32) # one-hot encoding\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# BATCH_SIZE * 32 * 32 * 1\n",
    "# conv1: 5 * 5 * 1 * 8\n",
    "# BATCH_SIZE * 16 * 16 * 8\n",
    "# conv2: 5 * 5 * 8 * 16\n",
    "# BATCH_SIZE * 8 * 8 * 16\n",
    "# conv3: 5 * 5 * 16 * 32\n",
    "# BATCH_SIZE * 4 * 4 * 32\n",
    "# fc1: 512 * 64\n",
    "# BATCH_SIZE * 64\n",
    "# fc2: 64 * 10 \n",
    "# BATCH_SIZE * 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def equal(a):\n",
    "    offset = 6\n",
    "    return a[0] == a[offset] and all(a[i] == a[i+offset] for i in range(1, 6))\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    result = np.apply_along_axis(equal, 1, np.hstack((predictions, labels)))\n",
    "    return tf.reduce_mean(np.cast(result, np.float32)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PATCH_SIZE = 5\n",
    "DEPTH_1 = 24\n",
    "DEPTH_2 = 48\n",
    "DEPTH_3 = 80\n",
    "NUM_HIDDEN = 128\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(None, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "    tf_train_labels = tf.placeholder(tf.int64, shape=(None, NUM_DIGITS))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_valid_labels = tf.constant(valid_labels, dtype=tf.int64)\n",
    "    \n",
    "    conv1_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS, DEPTH_1], stddev=0.1), name='conv1_weights')\n",
    "    conv1_biases = tf.Variable(tf.zeros([DEPTH_1]), name='conv1_biases')\n",
    "    conv2_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, DEPTH_1, DEPTH_2], stddev=0.1), name='conv2_weights')\n",
    "    conv2_biases = tf.Variable(tf.zeros([DEPTH_2]), name='conv2_biases')\n",
    "    conv3_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, DEPTH_2, DEPTH_3], stddev=0.1), name='conv3_weights')\n",
    "    conv3_biases = tf.Variable(tf.zeros([DEPTH_3]), name='conv3_biases')\n",
    "    fc1_weights = tf.Variable(tf.truncated_normal([IMAGE_SIZE//8 * IMAGE_SIZE//8 * DEPTH_3, NUM_HIDDEN], stddev=0.1), name='fc1_weights')\n",
    "    fc1_biases = tf.Variable(tf.constant(1.0, shape=[NUM_HIDDEN]), name='fc1_biases')\n",
    "    \n",
    "    #fc_numdigit_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, MAX_NUM_DIGIT], stddev=0.1))\n",
    "    #fc_numdigit_biases = tf.Variable(tf.constant(1.0, shape=[MAX_NUM_DIGIT]))\n",
    "    fc_digit1_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1), name='fc_digit1_weights')\n",
    "    fc_digit1_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]), name='fc_digit1_biases')\n",
    "    fc_digit2_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1), name='fc_digit2_weights')\n",
    "    fc_digit2_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]), name='fc_digit2_biases')\n",
    "    fc_digit3_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1), name='fc_digit3_weights')\n",
    "    fc_digit3_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]), name='fc_digit3_biases')\n",
    "    fc_digit4_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1), name='fc_digit4_weights')\n",
    "    fc_digit4_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]), name='fc_digit4_biases')\n",
    "    fc_digit5_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1), name='fc_digit5_weights')\n",
    "    fc_digit5_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]), name='fc_digit5_biases')\n",
    "    \n",
    "    saver = tf.train.Saver(tf.trainable_variables()) # defaults to saving all variables\n",
    "    \n",
    "    def model(data, train=False):\n",
    "        conv = tf.nn.conv2d(data, conv1_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv = tf.nn.conv2d(pool, conv2_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv = tf.nn.conv2d(pool, conv3_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv3_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        shape = pool.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool, [-1, shape[1]*shape[2]*shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "        \n",
    "        if train:\n",
    "            hidden = tf.nn.dropout(hidden, 0.8, seed=SEED)\n",
    "            \n",
    "        #logit_numdigit = tf.matmul(hidden, fc_numdigit_weights) + fc_numdigit_biases\n",
    "        logit_digit1 = tf.matmul(hidden, fc_digit1_weights) + fc_digit1_biases\n",
    "        logit_digit2 = tf.matmul(hidden, fc_digit2_weights) + fc_digit2_biases\n",
    "        logit_digit3 = tf.matmul(hidden, fc_digit3_weights) + fc_digit3_biases\n",
    "        logit_digit4 = tf.matmul(hidden, fc_digit4_weights) + fc_digit4_biases\n",
    "        logit_digit5 = tf.matmul(hidden, fc_digit5_weights) + fc_digit5_biases\n",
    "        \n",
    "        return logit_digit1, logit_digit2, logit_digit3, logit_digit4, logit_digit5\n",
    "    \n",
    "    def predict(logits):\n",
    "        return tf.transpose(tf.pack([tf.argmax(logits[0], 1), tf.argmax(logits[1], 1), tf.argmax(logits[2], 1), \\\n",
    "                        tf.argmax(logits[3], 1), tf.argmax(logits[4], 1)]))\n",
    "        # return tf.pack([tf.argmax(logits[0], 1), tf.argmax(logits[1], 1), tf.argmax(logits[2], 1), \\\n",
    "                       # tf.argmax(logits[3], 1), tf.argmax(logits[4], 1)], axis=1)\n",
    "    \n",
    "    def accuracy(predictions, labels):\n",
    "        return tf.reduce_mean(tf.cast(tf.reduce_all(tf.equal(predictions, labels), reduction_indices=1), tf.float32)) * 100\n",
    "    \n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[0], tf_train_labels[:, 0])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[1], tf_train_labels[:, 1])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[2], tf_train_labels[:, 2])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[3], tf_train_labels[:, 3])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[4], tf_train_labels[:, 4]))\n",
    "    \n",
    "    regularizers = tf.nn.l2_loss(fc1_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit1_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit2_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit3_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit4_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit5_weights)\n",
    "                \n",
    "    loss += 1e-3 * regularizers\n",
    "    \n",
    "    batch = tf.Variable(0, dtype=tf.float32)\n",
    "    #decayed_learning_rate = learning_rate *\n",
    "    #                    decay_rate ^ (global_step / decay_steps)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        0.04, # Base learning rate\n",
    "        batch * BATCH_SIZE, # Current index into the dataset\n",
    "        train_labels.shape[0], # Decay step\n",
    "        0.9, # Decay rate,\n",
    "        staircase=True\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "    \n",
    "    train_prediction = predict(logits)\n",
    "    valid_prediction = predict(model(tf_valid_dataset))\n",
    "    \n",
    "    #tf.Print(train_prediction, [train_prediction])\n",
    "    \n",
    "    train_accuracy = accuracy(train_prediction, tf_train_labels)\n",
    "    valid_accuracy = accuracy(valid_prediction, tf_valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_in_unison_inplace(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_boolean('training', True, 'If true do the training else load already trained model.')\n",
    "flags.DEFINE_string('checkpoint_dir', 'model/', 'Checkpoint directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Random shuffle\n",
      "Minibatch loss at step 0: 64.269798, learning rate: 0.040000, 1.590s\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 500: 4.351222, learning rate: 0.040000, 12.170s\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 21.8%\n",
      "Minibatch loss at step 1000: 2.781978, learning rate: 0.040000, 12.152s\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 43.0%\n",
      "Minibatch loss at step 1500: 2.549631, learning rate: 0.040000, 12.139s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 53.6%\n",
      "Minibatch loss at step 2000: 2.672587, learning rate: 0.040000, 12.153s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 59.4%\n",
      "Minibatch loss at step 2500: 2.393546, learning rate: 0.040000, 12.153s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 64.2%\n",
      "Minibatch loss at step 3000: 1.552931, learning rate: 0.040000, 12.140s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 62.0%\n",
      "Random shuffle\n",
      "Minibatch loss at step 3500: 1.249791, learning rate: 0.038000, 12.726s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 65.4%\n",
      "Minibatch loss at step 4000: 1.937248, learning rate: 0.038000, 12.192s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 66.4%\n",
      "Minibatch loss at step 4500: 1.666833, learning rate: 0.038000, 12.142s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 68.8%\n",
      "Minibatch loss at step 5000: 1.760464, learning rate: 0.038000, 12.201s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 71.6%\n",
      "Minibatch loss at step 5500: 1.570106, learning rate: 0.038000, 12.138s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 71.4%\n",
      "Minibatch loss at step 6000: 1.572204, learning rate: 0.038000, 12.143s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 71.8%\n",
      "Random shuffle\n",
      "Minibatch loss at step 6500: 1.428458, learning rate: 0.036100, 12.642s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 7000: 1.253147, learning rate: 0.036100, 12.317s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 7500: 0.887022, learning rate: 0.036100, 12.164s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 73.4%\n",
      "Minibatch loss at step 8000: 1.875457, learning rate: 0.036100, 12.137s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 8500: 0.974293, learning rate: 0.036100, 12.141s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 9000: 1.126674, learning rate: 0.036100, 12.161s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 9500: 1.255026, learning rate: 0.036100, 12.152s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 75.8%\n",
      "Random shuffle\n",
      "Minibatch loss at step 10000: 1.014540, learning rate: 0.034295, 12.658s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 10500: 1.380032, learning rate: 0.034295, 12.176s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 11000: 0.866278, learning rate: 0.034295, 12.143s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 11500: 1.613180, learning rate: 0.034295, 12.152s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 12000: 1.289043, learning rate: 0.034295, 12.134s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 12500: 0.870955, learning rate: 0.034295, 12.136s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 77.2%\n",
      "Random shuffle\n",
      "Minibatch loss at step 13000: 0.969693, learning rate: 0.032580, 12.633s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 13500: 1.031088, learning rate: 0.032580, 12.127s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 14000: 0.695132, learning rate: 0.032580, 12.164s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 14500: 1.191869, learning rate: 0.032580, 12.198s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 15000: 1.076814, learning rate: 0.032580, 12.141s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 15500: 0.915156, learning rate: 0.032580, 12.137s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.4%\n",
      "Random shuffle\n",
      "Minibatch loss at step 16000: 1.137190, learning rate: 0.030951, 12.632s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 16500: 0.651527, learning rate: 0.030951, 12.239s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 17000: 0.888483, learning rate: 0.030951, 12.173s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 17500: 0.749841, learning rate: 0.030951, 12.147s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 18000: 1.057254, learning rate: 0.030951, 12.140s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 18500: 0.645397, learning rate: 0.030951, 12.147s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 19000: 1.449180, learning rate: 0.030951, 12.139s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 77.8%\n",
      "Random shuffle\n",
      "Minibatch loss at step 19500: 0.820967, learning rate: 0.029404, 12.718s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 20000: 1.569267, learning rate: 0.029404, 12.146s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 20500: 0.869204, learning rate: 0.029404, 12.141s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 21000: 0.857963, learning rate: 0.029404, 12.137s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 21500: 0.576121, learning rate: 0.029404, 12.178s\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 22000: 0.629246, learning rate: 0.029404, 12.139s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.8%\n",
      "Random shuffle\n",
      "Minibatch loss at step 22500: 0.922863, learning rate: 0.027933, 12.634s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 23000: 0.716150, learning rate: 0.027933, 12.142s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 23500: 1.661212, learning rate: 0.027933, 12.147s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 24000: 0.595502, learning rate: 0.027933, 12.178s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 24500: 0.530902, learning rate: 0.027933, 12.140s\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 25000: 0.918212, learning rate: 0.027933, 12.132s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Random shuffle\n",
      "Minibatch loss at step 25500: 0.532614, learning rate: 0.026537, 12.628s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 26000: 0.585920, learning rate: 0.026537, 12.146s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 26500: 0.869845, learning rate: 0.026537, 12.139s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 27000: 0.552635, learning rate: 0.026537, 12.132s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 27500: 0.948289, learning rate: 0.026537, 12.128s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 28000: 0.963105, learning rate: 0.026537, 12.138s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 28500: 0.706310, learning rate: 0.026537, 12.152s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.6%\n",
      "Random shuffle\n",
      "Minibatch loss at step 29000: 0.614398, learning rate: 0.025210, 12.731s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 29500: 0.571831, learning rate: 0.025210, 12.175s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 30000: 0.502222, learning rate: 0.025210, 12.164s\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 81.2%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "NUM_STEPS = 30001\n",
    "SHOW_STATE_AFTER = 500\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    offset = 0\n",
    "    for step in range(NUM_STEPS):\n",
    "        if(offset == 0):\n",
    "            train_dataset, train_labels = shuffle_in_unison_inplace(train_dataset, train_labels)\n",
    "            print('Random shuffle')\n",
    "        feed_dict = {\n",
    "            tf_train_dataset : train_dataset[offset:(offset + BATCH_SIZE)], \n",
    "            tf_train_labels : train_labels[offset:(offset + BATCH_SIZE)]\n",
    "        }\n",
    "        offset += BATCH_SIZE\n",
    "        if offset+BATCH_SIZE > train_labels.shape[0]:\n",
    "            offset = 0\n",
    "        _, l, lr = session.run([optimizer, loss, learning_rate], feed_dict=feed_dict)\n",
    "        if (step % SHOW_STATE_AFTER == 0):\n",
    "            train_acc, valid_acc = session.run([train_accuracy, valid_accuracy], feed_dict=feed_dict)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            start_time = time.time()\n",
    "            print('Minibatch loss at step %d: %f, learning rate: %.6f, %.3fs' % (step, l, lr, elapsed_time))\n",
    "            train_accuracies.append(train_acc)\n",
    "            print('Minibatch accuracy: %.1f%%' % train_accuracies[-1])\n",
    "            valid_accuracies.append(valid_acc)\n",
    "            print('Validation accuracy: %.1f%%' % valid_accuracies[-1])\n",
    "    saver.save(session, 'multi.ckpt', write_meta_graph=False)\n",
    "    #predictions = test_prediction.eval()\n",
    "    #print('Test accuracy: %.1f%%' % test_accuracy.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6fcb24b978>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGHCAYAAACu1mg/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fd0a71128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, NUM_STEPS, SHOW_STATE_AFTER), train_accuracies)\n",
    "plt.plot(range(0, NUM_STEPS, SHOW_STATE_AFTER), valid_accuracies)\n",
    "plt.title('Learning curve')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.legend(['Train accuracy', 'Valid accuracy'], loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "    tf_train_labels = tf.placeholder(tf.int64, shape=(BATCH_SIZE, NUM_DIGITS))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_valid_labels = tf.constant(valid_labels, dtype=tf.int64)\n",
    "    \n",
    "    conv1_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS, DEPTH_1], stddev=0.1))\n",
    "    conv1_biases = tf.Variable(tf.zeros([DEPTH_1]))\n",
    "    conv2_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, DEPTH_1, DEPTH_2], stddev=0.1))\n",
    "    conv2_biases = tf.Variable(tf.zeros([DEPTH_2]))\n",
    "    conv3_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, DEPTH_2, DEPTH_3], stddev=0.1))\n",
    "    conv3_biases = tf.Variable(tf.zeros([DEPTH_3]))\n",
    "    fc1_weights = tf.Variable(tf.truncated_normal([IMAGE_SIZE//8 * IMAGE_SIZE//8 * DEPTH_3, NUM_HIDDEN], stddev=0.1))\n",
    "    fc1_biases = tf.Variable(tf.constant(1.0, shape=[NUM_HIDDEN]))\n",
    "    \n",
    "    #fc_numdigit_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, MAX_NUM_DIGIT], stddev=0.1))\n",
    "    #fc_numdigit_biases = tf.Variable(tf.constant(1.0, shape=[MAX_NUM_DIGIT]))\n",
    "    fc_digit1_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit1_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit2_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit2_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit3_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit3_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit4_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit4_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit5_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit5_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    \n",
    "    saver = tf.train.Saver(tf.trainable_variables()) # defaults to saving all variables\n",
    "    \n",
    "    def model(data, train=False):\n",
    "        conv = tf.nn.conv2d(data, conv1_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv = tf.nn.conv2d(pool, conv2_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv = tf.nn.conv2d(pool, conv3_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv3_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        shape = pool.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool, [shape[0], shape[1]*shape[2]*shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "        \n",
    "        if train:\n",
    "            hidden = tf.nn.dropout(hidden, 0.9, seed=SEED)\n",
    "            \n",
    "        #logit_numdigit = tf.matmul(hidden, fc_numdigit_weights) + fc_numdigit_biases\n",
    "        logit_digit1 = tf.matmul(hidden, fc_digit1_weights) + fc_digit1_biases\n",
    "        logit_digit2 = tf.matmul(hidden, fc_digit2_weights) + fc_digit2_biases\n",
    "        logit_digit3 = tf.matmul(hidden, fc_digit3_weights) + fc_digit3_biases\n",
    "        logit_digit4 = tf.matmul(hidden, fc_digit4_weights) + fc_digit4_biases\n",
    "        logit_digit5 = tf.matmul(hidden, fc_digit5_weights) + fc_digit5_biases\n",
    "        \n",
    "        return logit_digit1, logit_digit2, logit_digit3, logit_digit4, logit_digit5\n",
    "    \n",
    "    def predict(logits):\n",
    "        return tf.transpose(tf.pack([tf.argmax(logits[0], 1), tf.argmax(logits[1], 1), tf.argmax(logits[2], 1), \\\n",
    "                        tf.argmax(logits[3], 1), tf.argmax(logits[4], 1)]))\n",
    "        # return tf.pack([tf.argmax(logits[0], 1), tf.argmax(logits[1], 1), tf.argmax(logits[2], 1), \\\n",
    "                       # tf.argmax(logits[3], 1), tf.argmax(logits[4], 1)], axis=1)\n",
    "    \n",
    "    def accuracy(predictions, labels):\n",
    "        return tf.reduce_mean(tf.cast(tf.reduce_all(tf.equal(predictions, labels), reduction_indices=1), tf.float32)) * 100\n",
    "    \n",
    "    logits = model(tf_train_dataset, True)\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[0], tf_train_labels[:, 0])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[1], tf_train_labels[:, 1])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[2], tf_train_labels[:, 2])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[3], tf_train_labels[:, 3])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[4], tf_train_labels[:, 4]))\n",
    "    \n",
    "    regularizers = tf.nn.l2_loss(fc1_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit1_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit2_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit3_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit4_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit5_weights)\n",
    "                \n",
    "    loss += 5e-4 * regularizers\n",
    "    \n",
    "    batch = tf.Variable(0, dtype=tf.float32)\n",
    "    #decayed_learning_rate = learning_rate *\n",
    "    #                    decay_rate ^ (global_step / decay_steps)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        0.01, # Base learning rate\n",
    "        batch * BATCH_SIZE, # Current index into the dataset\n",
    "        train_labels.shape[0], # Decay step\n",
    "        0.9, # Decay rate,\n",
    "        staircase=True\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "    \n",
    "    train_prediction = predict(logits)\n",
    "    valid_prediction = predict(model(tf_valid_dataset))\n",
    "    \n",
    "    #tf.Print(train_prediction, [train_prediction])\n",
    "    \n",
    "    train_accuracy = accuracy(train_prediction, tf_train_labels)\n",
    "    valid_accuracy = accuracy(valid_prediction, tf_valid_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "num_steps = 10001\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    saver.restore(session, 'multi3.ckpt')\n",
    "    offset = 0\n",
    "    for step in range(num_steps):\n",
    "        if(offset == 0):\n",
    "            train_dataset, train_labels = shuffle_in_unison_inplace(train_dataset, train_labels)\n",
    "            print('Random shuffle')\n",
    "        feed_dict = {\n",
    "            tf_train_dataset : train_dataset[offset:(offset + BATCH_SIZE)], \n",
    "            tf_train_labels : train_labels[offset:(offset + BATCH_SIZE)]\n",
    "        }\n",
    "        offset += BATCH_SIZE\n",
    "        if offset+BATCH_SIZE > train_labels.shape[0]:\n",
    "            offset = 0\n",
    "        _, l, lr, train_acc, valid_acc = \\\n",
    "            session.run([optimizer, loss, learning_rate, train_accuracy, valid_accuracy], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            elapsed_time = time.time() - start_time\n",
    "            start_time = time.time()\n",
    "            print('Minibatch loss at step %d: %f, learning rate: %.6f, %.3fs' % (step, l, lr, elapsed_time))\n",
    "            train_accuracies.append(train_acc)\n",
    "            print('Minibatch accuracy: %.1f%%' % train_accuracies[-1])\n",
    "            valid_accuracies.append(valid_acc)\n",
    "            print('Validation accuracy: %.1f%%' % valid_accuracies[-1])\n",
    "    saver.save(session, 'multi4.ckpt', write_meta_graph=False)\n",
    "    #predictions = test_prediction.eval()\n",
    "    #print('Test accuracy: %.1f%%' % test_accuracy.eval())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
