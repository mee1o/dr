{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (33152, 32, 32)\n",
      "Training labels shape:  (33152, 5)\n",
      "Validing dataset shape:  (250, 32, 32)\n",
      "Validing labels shape:  (250, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'svhn_multi_train.pickle'\n",
    "VALID_SIZE = 500 / 2\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    train_dataset = dataset['dataset'][VALID_SIZE:]\n",
    "    train_labels = dataset['labels'][VALID_SIZE:, 1:6]\n",
    "    valid_dataset = dataset['dataset'][:VALID_SIZE]\n",
    "    valid_labels = dataset['labels'][:VALID_SIZE, 1:6]\n",
    "    \n",
    "print('Training dataset shape: ', train_dataset.shape)\n",
    "print('Training labels shape: ', train_labels.shape)\n",
    "print('Validing dataset shape: ', valid_dataset.shape)\n",
    "print('Validing labels shape: ', valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (202902, 32, 32)\n",
      "Training labels shape:  (202902, 5)\n",
      "Validing dataset shape:  (500, 32, 32)\n",
      "Validing labels shape:  (500, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/mnt/bin/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:8: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'svhn_multi_extra.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    train_dataset = np.vstack((train_dataset, dataset['dataset'][VALID_SIZE:170000]))\n",
    "    train_labels = np.vstack((train_labels, dataset['labels'][VALID_SIZE:170000, 1:6]))\n",
    "    valid_dataset = np.vstack((valid_dataset, dataset['dataset'][:VALID_SIZE]))\n",
    "    valid_labels = np.vstack((valid_labels, dataset['labels'][:VALID_SIZE, 1:6]))\n",
    "    \n",
    "print('Training dataset shape: ', train_dataset.shape)\n",
    "print('Training labels shape: ', train_labels.shape)\n",
    "print('Validing dataset shape: ', valid_dataset.shape)\n",
    "print('Validing labels shape: ', valid_labels.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  6, 10, 10, 10],\n",
       "       [ 3,  7,  0, 10, 10],\n",
       "       [ 1,  9, 10, 10, 10],\n",
       "       [ 3,  5, 10, 10, 10],\n",
       "       [ 9,  3, 10, 10, 10],\n",
       "       [ 2,  8, 10, 10, 10],\n",
       "       [ 1,  1, 10, 10, 10],\n",
       "       [ 5,  6, 10, 10, 10],\n",
       "       [ 5, 10, 10, 10, 10],\n",
       "       [ 3,  6, 10, 10, 10]], dtype=int8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (202902, 32, 32, 1) (202902, 5)\n",
      "Validation set (500, 32, 32, 1) (500, 5)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 32\n",
    "NUM_DIGITS = 5\n",
    "NUM_LABELS = 11 # 0-9 + 10==doesn't exist\n",
    "NUM_CHANNELS = 1 # grayscale\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)).astype(np.float32)\n",
    "    #labels = (np.array([10,1,2,3,4,5,6,7,8,9]) == labels).astype(np.float32) # one-hot encoding\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE * 32 * 32 * 1\n",
    "# conv1: 5 * 5 * 1 * 8\n",
    "# BATCH_SIZE * 16 * 16 * 8\n",
    "# conv2: 5 * 5 * 8 * 16\n",
    "# BATCH_SIZE * 8 * 8 * 16\n",
    "# conv3: 5 * 5 * 16 * 32\n",
    "# BATCH_SIZE * 4 * 4 * 32\n",
    "# fc1: 512 * 64\n",
    "# BATCH_SIZE * 64\n",
    "# fc2: 64 * 10 \n",
    "# BATCH_SIZE * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def equal(a):\n",
    "    offset = 6\n",
    "    return a[0] == a[offset] and all(a[i] == a[i+offset] for i in range(1, 6))\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    result = np.apply_along_axis(equal, 1, np.hstack((predictions, labels)))\n",
    "    return tf.reduce_mean(np.cast(result, np.float32)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PATCH_SIZE = 5\n",
    "DEPTH_1 = 16\n",
    "DEPTH_2 = 32\n",
    "DEPTH_3 = 64\n",
    "NUM_HIDDEN = 128\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "    tf_train_labels = tf.placeholder(tf.int64, shape=(BATCH_SIZE, NUM_DIGITS))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_valid_labels = tf.constant(valid_labels, dtype=tf.int64)\n",
    "    \n",
    "    conv1_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS, DEPTH_1], stddev=0.1))\n",
    "    conv1_biases = tf.Variable(tf.zeros([DEPTH_1]))\n",
    "    conv2_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, DEPTH_1, DEPTH_2], stddev=0.1))\n",
    "    conv2_biases = tf.Variable(tf.zeros([DEPTH_2]))\n",
    "    conv3_weights = tf.Variable(tf.truncated_normal([PATCH_SIZE, PATCH_SIZE, DEPTH_2, DEPTH_3], stddev=0.1))\n",
    "    conv3_biases = tf.Variable(tf.zeros([DEPTH_3]))\n",
    "    fc1_weights = tf.Variable(tf.truncated_normal([IMAGE_SIZE//8 * IMAGE_SIZE//8 * DEPTH_3, NUM_HIDDEN], stddev=0.1))\n",
    "    fc1_biases = tf.Variable(tf.constant(1.0, shape=[NUM_HIDDEN]))\n",
    "    \n",
    "    #fc_numdigit_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, MAX_NUM_DIGIT], stddev=0.1))\n",
    "    #fc_numdigit_biases = tf.Variable(tf.constant(1.0, shape=[MAX_NUM_DIGIT]))\n",
    "    fc_digit1_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit1_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit2_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit2_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit3_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit3_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit4_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit4_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    fc_digit5_weights = tf.Variable(tf.truncated_normal([NUM_HIDDEN, NUM_LABELS], stddev=0.1))\n",
    "    fc_digit5_biases = tf.Variable(tf.constant(1.0, shape=[NUM_LABELS]))\n",
    "    \n",
    "    saver = tf.train.Saver(tf.trainable_variables()) # defaults to saving all variables\n",
    "    \n",
    "    def model(data, train=False):\n",
    "        conv = tf.nn.conv2d(data, conv1_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv = tf.nn.conv2d(pool, conv2_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv = tf.nn.conv2d(pool, conv3_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        relu = tf.nn.relu(tf.nn.bias_add(conv, conv3_biases))\n",
    "        pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        shape = pool.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool, [shape[0], shape[1]*shape[2]*shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "        \n",
    "        if train:\n",
    "            hidden = tf.nn.dropout(hidden, 0.8, seed=SEED)\n",
    "            \n",
    "        #logit_numdigit = tf.matmul(hidden, fc_numdigit_weights) + fc_numdigit_biases\n",
    "        logit_digit1 = tf.matmul(hidden, fc_digit1_weights) + fc_digit1_biases\n",
    "        logit_digit2 = tf.matmul(hidden, fc_digit2_weights) + fc_digit2_biases\n",
    "        logit_digit3 = tf.matmul(hidden, fc_digit3_weights) + fc_digit3_biases\n",
    "        logit_digit4 = tf.matmul(hidden, fc_digit4_weights) + fc_digit4_biases\n",
    "        logit_digit5 = tf.matmul(hidden, fc_digit5_weights) + fc_digit5_biases\n",
    "        \n",
    "        return logit_digit1, logit_digit2, logit_digit3, logit_digit4, logit_digit5\n",
    "    \n",
    "    def predict(logits):\n",
    "        return tf.transpose(tf.pack([tf.argmax(logits[0], 1), tf.argmax(logits[1], 1), tf.argmax(logits[2], 1), \\\n",
    "                        tf.argmax(logits[3], 1), tf.argmax(logits[4], 1)]))\n",
    "        # return tf.pack([tf.argmax(logits[0], 1), tf.argmax(logits[1], 1), tf.argmax(logits[2], 1), \\\n",
    "                       # tf.argmax(logits[3], 1), tf.argmax(logits[4], 1)], axis=1)\n",
    "    \n",
    "    def accuracy(predictions, labels):\n",
    "        return tf.reduce_mean(tf.cast(tf.reduce_all(tf.equal(predictions, labels), reduction_indices=1), tf.float32)) * 100\n",
    "    \n",
    "    logits = model(tf_train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[0], tf_train_labels[:, 0])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[1], tf_train_labels[:, 1])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[2], tf_train_labels[:, 2])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[3], tf_train_labels[:, 3])) + \\\n",
    "            tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits[4], tf_train_labels[:, 4]))\n",
    "    \n",
    "    regularizers = tf.nn.l2_loss(fc1_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit1_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit2_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit3_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit4_weights) + \\\n",
    "                tf.nn.l2_loss(fc_digit5_weights)\n",
    "                \n",
    "    loss += 5e-4 * regularizers\n",
    "    \n",
    "    batch = tf.Variable(0, dtype=tf.float32)\n",
    "    #decayed_learning_rate = learning_rate *\n",
    "    #                    decay_rate ^ (global_step / decay_steps)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        0.04, # Base learning rate\n",
    "        batch * BATCH_SIZE, # Current index into the dataset\n",
    "        train_labels.shape[0], # Decay step\n",
    "        0.95, # Decay rate,\n",
    "        staircase=True\n",
    "    )\n",
    "    \n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "    \n",
    "    train_prediction = predict(logits)\n",
    "    valid_prediction = predict(model(tf_valid_dataset))\n",
    "    \n",
    "    #tf.Print(train_prediction, [train_prediction])\n",
    "    \n",
    "    train_accuracy = accuracy(train_prediction, tf_train_labels)\n",
    "    valid_accuracy = accuracy(valid_prediction, tf_valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_in_unison_inplace(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_boolean('training', True, 'If true do the training else load already trained model.')\n",
    "flags.DEFINE_string('checkpoint_dir', 'model/', 'Checkpoint directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Random shuffle\n",
      "Minibatch loss at step 0: 34.836143, learning rate: 0.040000, 1.481s\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.0%\n",
      "Minibatch loss at step 50: 6.463960, learning rate: 0.040000, 1.684s\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 3.8%\n",
      "Minibatch loss at step 100: 5.992064, learning rate: 0.040000, 1.684s\n",
      "Minibatch accuracy: 3.1%\n",
      "Validation accuracy: 5.6%\n",
      "Minibatch loss at step 150: 5.337341, learning rate: 0.040000, 1.686s\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 8.4%\n",
      "Minibatch loss at step 200: 4.937343, learning rate: 0.040000, 1.684s\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 17.6%\n",
      "Minibatch loss at step 250: 4.627532, learning rate: 0.040000, 1.683s\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 16.0%\n",
      "Minibatch loss at step 300: 3.546866, learning rate: 0.040000, 1.681s\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 21.4%\n",
      "Minibatch loss at step 350: 3.662126, learning rate: 0.040000, 1.681s\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 29.2%\n",
      "Minibatch loss at step 400: 3.910064, learning rate: 0.040000, 1.682s\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 30.6%\n",
      "Minibatch loss at step 450: 2.804354, learning rate: 0.040000, 1.683s\n",
      "Minibatch accuracy: 39.1%\n",
      "Validation accuracy: 35.2%\n",
      "Minibatch loss at step 500: 3.371815, learning rate: 0.040000, 1.684s\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 37.6%\n",
      "Minibatch loss at step 550: 3.505804, learning rate: 0.040000, 1.682s\n",
      "Minibatch accuracy: 40.6%\n",
      "Validation accuracy: 39.6%\n",
      "Minibatch loss at step 600: 3.076679, learning rate: 0.040000, 1.684s\n",
      "Minibatch accuracy: 45.3%\n",
      "Validation accuracy: 41.2%\n",
      "Minibatch loss at step 650: 2.662056, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 45.4%\n",
      "Minibatch loss at step 700: 2.593664, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 46.2%\n",
      "Minibatch loss at step 750: 3.042928, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 45.3%\n",
      "Validation accuracy: 46.2%\n",
      "Minibatch loss at step 800: 2.753615, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 44.6%\n",
      "Minibatch loss at step 850: 2.085593, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 47.8%\n",
      "Minibatch loss at step 900: 2.447300, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 49.6%\n",
      "Minibatch loss at step 950: 2.576999, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 52.6%\n",
      "Minibatch loss at step 1000: 2.058264, learning rate: 0.040000, 1.678s\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 53.2%\n",
      "Minibatch loss at step 1050: 2.225945, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 53.0%\n",
      "Minibatch loss at step 1100: 2.084126, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 54.4%\n",
      "Minibatch loss at step 1150: 2.061482, learning rate: 0.040000, 1.682s\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 55.2%\n",
      "Minibatch loss at step 1200: 2.277232, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 55.0%\n",
      "Minibatch loss at step 1250: 2.203948, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 53.2%\n",
      "Minibatch loss at step 1300: 2.404906, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 57.0%\n",
      "Minibatch loss at step 1350: 2.501751, learning rate: 0.040000, 1.681s\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 58.6%\n",
      "Minibatch loss at step 1400: 2.188649, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 58.8%\n",
      "Minibatch loss at step 1450: 2.067453, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 57.4%\n",
      "Minibatch loss at step 1500: 1.937747, learning rate: 0.040000, 1.681s\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 59.6%\n",
      "Minibatch loss at step 1550: 1.867099, learning rate: 0.040000, 1.678s\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 59.4%\n",
      "Minibatch loss at step 1600: 2.209176, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 60.8%\n",
      "Minibatch loss at step 1650: 2.089536, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 57.2%\n",
      "Minibatch loss at step 1700: 1.905977, learning rate: 0.040000, 1.683s\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 1750: 2.062304, learning rate: 0.040000, 1.682s\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 60.0%\n",
      "Minibatch loss at step 1800: 2.146138, learning rate: 0.040000, 1.678s\n",
      "Minibatch accuracy: 51.6%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 1850: 1.529986, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 1900: 1.998826, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 63.8%\n",
      "Minibatch loss at step 1950: 1.768327, learning rate: 0.040000, 1.695s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 62.4%\n",
      "Minibatch loss at step 2000: 1.518168, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 65.4%\n",
      "Minibatch loss at step 2050: 2.164887, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 61.4%\n",
      "Minibatch loss at step 2100: 1.574271, learning rate: 0.040000, 1.678s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 63.8%\n",
      "Minibatch loss at step 2150: 2.220077, learning rate: 0.040000, 1.682s\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 64.0%\n",
      "Minibatch loss at step 2200: 2.030861, learning rate: 0.040000, 1.678s\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 64.2%\n",
      "Minibatch loss at step 2250: 1.841663, learning rate: 0.040000, 1.682s\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 65.0%\n",
      "Minibatch loss at step 2300: 1.770643, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 65.2%\n",
      "Minibatch loss at step 2350: 1.818466, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 65.8%\n",
      "Minibatch loss at step 2400: 1.798995, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 67.4%\n",
      "Minibatch loss at step 2450: 1.619580, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 65.2%\n",
      "Minibatch loss at step 2500: 1.524023, learning rate: 0.040000, 1.678s\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 68.2%\n",
      "Minibatch loss at step 2550: 1.623180, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 67.0%\n",
      "Minibatch loss at step 2600: 1.796829, learning rate: 0.040000, 1.678s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 68.0%\n",
      "Minibatch loss at step 2650: 1.605384, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 67.2%\n",
      "Minibatch loss at step 2700: 1.552790, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 67.0%\n",
      "Minibatch loss at step 2750: 1.513604, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 69.6%\n",
      "Minibatch loss at step 2800: 1.604739, learning rate: 0.040000, 1.681s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 66.4%\n",
      "Minibatch loss at step 2850: 1.366785, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 68.8%\n",
      "Minibatch loss at step 2900: 1.457142, learning rate: 0.040000, 1.679s\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 67.4%\n",
      "Minibatch loss at step 2950: 1.822345, learning rate: 0.040000, 1.681s\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 66.6%\n",
      "Minibatch loss at step 3000: 1.669779, learning rate: 0.040000, 1.680s\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 69.6%\n",
      "Minibatch loss at step 3050: 1.595966, learning rate: 0.040000, 1.682s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 68.6%\n",
      "Minibatch loss at step 3100: 1.348785, learning rate: 0.040000, 1.688s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 69.4%\n",
      "Minibatch loss at step 3150: 1.560890, learning rate: 0.040000, 1.687s\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 69.6%\n",
      "Random shuffle\n",
      "Minibatch loss at step 3200: 1.420553, learning rate: 0.038000, 1.977s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 69.6%\n",
      "Minibatch loss at step 3250: 1.428337, learning rate: 0.038000, 1.683s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 69.0%\n",
      "Minibatch loss at step 3300: 1.396474, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 3350: 1.547628, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 3400: 0.894250, learning rate: 0.038000, 1.682s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 71.0%\n",
      "Minibatch loss at step 3450: 1.506190, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 71.0%\n",
      "Minibatch loss at step 3500: 1.578879, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 69.4%\n",
      "Minibatch loss at step 3550: 1.525469, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 70.0%\n",
      "Minibatch loss at step 3600: 1.123428, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 70.4%\n",
      "Minibatch loss at step 3650: 1.005183, learning rate: 0.038000, 1.682s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 71.0%\n",
      "Minibatch loss at step 3700: 1.320543, learning rate: 0.038000, 1.684s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 69.0%\n",
      "Minibatch loss at step 3750: 1.287925, learning rate: 0.038000, 1.682s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 70.6%\n",
      "Minibatch loss at step 3800: 1.713971, learning rate: 0.038000, 1.682s\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 71.0%\n",
      "Minibatch loss at step 3850: 1.188359, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 71.6%\n",
      "Minibatch loss at step 3900: 1.353180, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 70.2%\n",
      "Minibatch loss at step 3950: 1.203171, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 70.2%\n",
      "Minibatch loss at step 4000: 1.886446, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 69.8%\n",
      "Minibatch loss at step 4050: 1.548205, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 4100: 1.344454, learning rate: 0.038000, 1.682s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 72.0%\n",
      "Minibatch loss at step 4150: 1.473483, learning rate: 0.038000, 1.683s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 4200: 1.151942, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 72.4%\n",
      "Minibatch loss at step 4250: 1.050905, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 4300: 1.261476, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 4350: 1.041810, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 72.8%\n",
      "Minibatch loss at step 4400: 1.464521, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 73.0%\n",
      "Minibatch loss at step 4450: 1.221181, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 73.0%\n",
      "Minibatch loss at step 4500: 1.318500, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 4550: 0.909483, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 4600: 1.257583, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 72.8%\n",
      "Minibatch loss at step 4650: 0.879703, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 71.4%\n",
      "Minibatch loss at step 4700: 1.285010, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 72.8%\n",
      "Minibatch loss at step 4750: 1.348063, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 72.6%\n",
      "Minibatch loss at step 4800: 0.986869, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 4850: 1.125010, learning rate: 0.038000, 1.677s\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 4900: 1.340621, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 4950: 1.335998, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 5000: 1.235161, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 73.6%\n",
      "Minibatch loss at step 5050: 0.959870, learning rate: 0.038000, 1.676s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 73.6%\n",
      "Minibatch loss at step 5100: 1.064128, learning rate: 0.038000, 1.677s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 71.4%\n",
      "Minibatch loss at step 5150: 1.029231, learning rate: 0.038000, 1.677s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 72.6%\n",
      "Minibatch loss at step 5200: 1.242938, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 73.4%\n",
      "Minibatch loss at step 5250: 1.155593, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 5300: 1.098748, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.2%\n",
      "Minibatch loss at step 5350: 1.262837, learning rate: 0.038000, 1.681s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 72.8%\n",
      "Minibatch loss at step 5400: 1.096304, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 5450: 1.115808, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 5500: 1.126630, learning rate: 0.038000, 1.680s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 73.4%\n",
      "Minibatch loss at step 5550: 1.317789, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 5600: 1.395736, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 5650: 1.187168, learning rate: 0.038000, 1.682s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 5700: 1.649753, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 72.6%\n",
      "Minibatch loss at step 5750: 1.089985, learning rate: 0.038000, 1.676s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 73.4%\n",
      "Minibatch loss at step 5800: 0.758286, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 5850: 1.101626, learning rate: 0.038000, 1.676s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 5900: 0.709841, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 5950: 0.911950, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 73.6%\n",
      "Minibatch loss at step 6000: 1.447394, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 6050: 1.084539, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 6100: 1.627108, learning rate: 0.038000, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 6150: 1.323575, learning rate: 0.038000, 1.677s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 6200: 0.839351, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 6250: 1.651014, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 6300: 1.210075, learning rate: 0.038000, 1.678s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.0%\n",
      "Random shuffle\n",
      "Minibatch loss at step 6350: 0.989523, learning rate: 0.036100, 1.980s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 6400: 0.710732, learning rate: 0.036100, 1.684s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 6450: 1.258192, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 6500: 1.227816, learning rate: 0.036100, 1.681s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 6550: 1.262825, learning rate: 0.036100, 1.684s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 6600: 1.528615, learning rate: 0.036100, 1.681s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss at step 6650: 1.406720, learning rate: 0.036100, 1.682s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 6700: 1.268436, learning rate: 0.036100, 1.681s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 6750: 0.747822, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 6800: 1.027270, learning rate: 0.036100, 1.687s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 6850: 1.150523, learning rate: 0.036100, 1.691s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 6900: 1.301047, learning rate: 0.036100, 1.683s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 6950: 1.117744, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 7000: 1.638056, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 7050: 1.037970, learning rate: 0.036100, 1.682s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 7100: 0.749569, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 7150: 0.914227, learning rate: 0.036100, 1.684s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 7200: 0.989618, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 7250: 1.401801, learning rate: 0.036100, 1.682s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 7300: 0.910346, learning rate: 0.036100, 1.681s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 7350: 0.839561, learning rate: 0.036100, 1.677s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 7400: 1.330290, learning rate: 0.036100, 1.684s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 7450: 0.676619, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 7500: 0.960530, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 7550: 1.240754, learning rate: 0.036100, 1.681s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 7600: 1.111789, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 7650: 0.870923, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 7700: 0.978781, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 7750: 1.351770, learning rate: 0.036100, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 7800: 1.093600, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 7850: 1.639091, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 7900: 0.987275, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 74.6%\n",
      "Minibatch loss at step 7950: 0.700534, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 8000: 0.863933, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 8050: 0.975928, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 8100: 0.753155, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 8150: 0.691355, learning rate: 0.036100, 1.682s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 8200: 1.497007, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 8250: 1.205113, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 8300: 1.238517, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 8350: 0.894932, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 8400: 0.865693, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 8450: 0.706702, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 8500: 1.373414, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 8550: 1.257514, learning rate: 0.036100, 1.679s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 8600: 1.311576, learning rate: 0.036100, 1.677s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 8650: 0.958578, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 8700: 0.832788, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 8750: 1.112317, learning rate: 0.036100, 1.681s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 8800: 1.209009, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 8850: 0.964697, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 8900: 0.911077, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 8950: 1.164198, learning rate: 0.036100, 1.677s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 9000: 0.938442, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 9050: 1.178379, learning rate: 0.036100, 1.683s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 9100: 0.730541, learning rate: 0.036100, 1.676s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 9150: 1.515022, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 9200: 0.908181, learning rate: 0.036100, 1.676s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 9250: 0.783244, learning rate: 0.036100, 1.677s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 9300: 0.971592, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 9350: 1.182050, learning rate: 0.036100, 1.680s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 9400: 1.109026, learning rate: 0.036100, 1.677s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 9450: 0.836618, learning rate: 0.036100, 1.677s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 9500: 1.340886, learning rate: 0.036100, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.4%\n",
      "Random shuffle\n",
      "Minibatch loss at step 9550: 1.107863, learning rate: 0.034295, 1.973s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 9600: 1.059684, learning rate: 0.034295, 1.681s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 9650: 1.073516, learning rate: 0.034295, 1.681s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 9700: 0.736509, learning rate: 0.034295, 1.684s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 9750: 0.710788, learning rate: 0.034295, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 9800: 1.274331, learning rate: 0.034295, 1.680s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 9850: 0.754205, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 9900: 1.473959, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 9950: 0.921654, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 10000: 0.718895, learning rate: 0.034295, 1.681s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 10050: 0.648154, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 10100: 0.909175, learning rate: 0.034295, 1.676s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 10150: 0.734544, learning rate: 0.034295, 1.680s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 10200: 1.119046, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 10250: 0.969377, learning rate: 0.034295, 1.676s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 10300: 0.769946, learning rate: 0.034295, 1.680s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 10350: 1.139532, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 10400: 0.640568, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 10450: 0.827382, learning rate: 0.034295, 1.676s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 10500: 1.188130, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 10550: 1.037327, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 10600: 0.798488, learning rate: 0.034295, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 10650: 0.822160, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 10700: 0.658288, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 10750: 1.092674, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 10800: 1.276204, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 10850: 0.974488, learning rate: 0.034295, 1.685s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 10900: 0.698260, learning rate: 0.034295, 1.681s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 10950: 1.285569, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 11000: 0.911239, learning rate: 0.034295, 1.675s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 11050: 0.701743, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 11100: 0.645857, learning rate: 0.034295, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 11150: 1.019792, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 11200: 0.963960, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 11250: 0.853794, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 11300: 0.885897, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 11350: 0.608641, learning rate: 0.034295, 1.676s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 11400: 0.826969, learning rate: 0.034295, 1.676s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 11450: 1.432159, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 11500: 0.713895, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 11550: 0.983181, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 11600: 0.768453, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 11650: 0.820378, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 11700: 0.643535, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 11750: 0.639697, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 11800: 0.866801, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 11850: 0.806250, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 11900: 1.247857, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 11950: 1.007247, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 12000: 1.002486, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 12050: 0.712150, learning rate: 0.034295, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 12100: 0.706791, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 12150: 0.936382, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 12200: 0.592548, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 12250: 0.567241, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 12300: 0.820658, learning rate: 0.034295, 1.676s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 12350: 0.728476, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 12400: 1.006712, learning rate: 0.034295, 1.675s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 12450: 0.599918, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 12500: 1.262050, learning rate: 0.034295, 1.677s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 12550: 0.710102, learning rate: 0.034295, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 12600: 0.925099, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 12650: 0.899958, learning rate: 0.034295, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 77.6%\n",
      "Random shuffle\n",
      "Minibatch loss at step 12700: 0.959271, learning rate: 0.032580, 1.979s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 12750: 0.644619, learning rate: 0.032580, 1.683s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 12800: 0.510729, learning rate: 0.032580, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 12850: 0.719726, learning rate: 0.032580, 1.682s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 12900: 0.643465, learning rate: 0.032580, 1.680s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 12950: 0.494736, learning rate: 0.032580, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 13000: 0.779957, learning rate: 0.032580, 1.681s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 13050: 0.756480, learning rate: 0.032580, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 13100: 1.023799, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 13150: 0.881021, learning rate: 0.032580, 1.683s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 13200: 0.902231, learning rate: 0.032580, 1.680s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 13250: 0.765000, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 13300: 0.634566, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 13350: 0.905561, learning rate: 0.032580, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 13400: 1.008161, learning rate: 0.032580, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 13450: 0.625100, learning rate: 0.032580, 1.676s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 13500: 0.890630, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 13550: 1.059864, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 13600: 1.082138, learning rate: 0.032580, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 13650: 0.659533, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 13700: 0.887686, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 13750: 0.486547, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 13800: 0.796780, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 13850: 1.127632, learning rate: 0.032580, 1.682s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 13900: 0.669475, learning rate: 0.032580, 1.681s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 13950: 0.803817, learning rate: 0.032580, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 14000: 0.459414, learning rate: 0.032580, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 14050: 0.667976, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 14100: 0.796922, learning rate: 0.032580, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 14150: 0.786118, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 14200: 0.668510, learning rate: 0.032580, 1.675s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 14250: 0.943271, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 14300: 0.704429, learning rate: 0.032580, 1.682s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 14350: 1.057001, learning rate: 0.032580, 1.676s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 14400: 0.678902, learning rate: 0.032580, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 14450: 0.890545, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 14500: 0.851484, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 14550: 0.744075, learning rate: 0.032580, 1.676s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 14600: 0.618439, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 14650: 0.468824, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 14700: 1.211332, learning rate: 0.032580, 1.680s\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 14750: 1.369261, learning rate: 0.032580, 1.674s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 14800: 1.252111, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 14850: 0.777995, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 14900: 0.689940, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 14950: 0.630352, learning rate: 0.032580, 1.676s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 15000: 0.775789, learning rate: 0.032580, 1.676s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 15050: 0.572176, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 15100: 0.541440, learning rate: 0.032580, 1.679s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 15150: 0.659312, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 15200: 1.014982, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 15250: 0.799728, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 15300: 0.881068, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 15350: 1.048067, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 15400: 0.577225, learning rate: 0.032580, 1.676s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 15450: 0.569266, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 15500: 1.037641, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 15550: 0.715650, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 15600: 0.475991, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 15650: 0.842561, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 15700: 0.633056, learning rate: 0.032580, 1.675s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 15750: 0.750194, learning rate: 0.032580, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 15800: 1.443067, learning rate: 0.032580, 1.677s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.8%\n",
      "Random shuffle\n",
      "Minibatch loss at step 15850: 0.958018, learning rate: 0.032580, 1.985s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 15900: 0.525254, learning rate: 0.030951, 1.693s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 15950: 1.062326, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 16000: 0.745091, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 16050: 0.511707, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 16100: 0.482668, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 16150: 0.728595, learning rate: 0.030951, 1.681s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 16200: 0.550260, learning rate: 0.030951, 1.683s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 16250: 0.906226, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 16300: 0.520287, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 16350: 0.771844, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 16400: 0.671021, learning rate: 0.030951, 1.683s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 16450: 0.678038, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 16500: 0.655496, learning rate: 0.030951, 1.681s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 16550: 0.593680, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 16600: 1.032701, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 16650: 0.835875, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 16700: 0.895315, learning rate: 0.030951, 1.681s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 16750: 0.535264, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 16800: 1.158745, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 16850: 1.397601, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 16900: 0.828866, learning rate: 0.030951, 1.684s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 16950: 0.803122, learning rate: 0.030951, 1.685s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 17000: 0.657507, learning rate: 0.030951, 1.689s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 17050: 0.845196, learning rate: 0.030951, 1.681s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 17100: 0.613804, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 17150: 0.605867, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 17200: 0.586886, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 17250: 0.632139, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 17300: 0.709870, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 17350: 0.518310, learning rate: 0.030951, 1.676s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 17400: 0.830370, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 17450: 0.545484, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 17500: 0.954751, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 17550: 0.711489, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 17600: 0.799933, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 17650: 0.716147, learning rate: 0.030951, 1.676s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 17700: 0.708923, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 17750: 0.486076, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 17800: 0.876346, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 17850: 0.551369, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 17900: 1.359648, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 17950: 1.116716, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 18000: 0.421220, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 18050: 1.060892, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 18100: 0.696344, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 18150: 0.674629, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 18200: 0.962300, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 18250: 0.831538, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 18300: 0.704787, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 18350: 0.985401, learning rate: 0.030951, 1.676s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 18400: 0.554068, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 18450: 0.759044, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 18500: 0.502826, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 18550: 0.641733, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 18600: 0.568234, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 18650: 0.623081, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 18700: 0.673638, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 18750: 0.847689, learning rate: 0.030951, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 18800: 0.963757, learning rate: 0.030951, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 18850: 0.925237, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 18900: 0.737322, learning rate: 0.030951, 1.675s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 18950: 0.736804, learning rate: 0.030951, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 19000: 0.840788, learning rate: 0.030951, 1.680s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.8%\n",
      "Random shuffle\n",
      "Minibatch loss at step 19050: 0.556901, learning rate: 0.029404, 1.976s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 19100: 1.302113, learning rate: 0.029404, 1.681s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 19150: 0.935075, learning rate: 0.029404, 1.681s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 19200: 0.780145, learning rate: 0.029404, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 19250: 0.858151, learning rate: 0.029404, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 19300: 0.452412, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 19350: 0.742390, learning rate: 0.029404, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 19400: 0.983079, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 19450: 0.561047, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 19500: 0.584795, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 19550: 0.761845, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 19600: 0.527097, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 19650: 0.507645, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 19700: 0.778481, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 19750: 0.652045, learning rate: 0.029404, 1.691s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 19800: 0.506843, learning rate: 0.029404, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 19850: 0.720703, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 19900: 1.073589, learning rate: 0.029404, 1.680s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 19950: 0.590111, learning rate: 0.029404, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 20000: 0.723800, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 20050: 0.330245, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 20100: 0.999060, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 20150: 0.678167, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 20200: 0.850377, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 20250: 0.675835, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 20300: 0.520636, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 20350: 0.317526, learning rate: 0.029404, 1.676s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 20400: 0.601516, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 20450: 0.949126, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 20500: 0.470140, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 20550: 0.735430, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 20600: 0.431375, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 20650: 0.780683, learning rate: 0.029404, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 20700: 0.607439, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 20750: 0.756774, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 20800: 0.716663, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 20850: 0.700714, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 20900: 0.505699, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 20950: 0.737601, learning rate: 0.029404, 1.676s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 21000: 0.599174, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 21050: 0.648761, learning rate: 0.029404, 1.676s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 21100: 0.693435, learning rate: 0.029404, 1.675s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 21150: 0.442135, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 21200: 0.945901, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 21250: 0.714054, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 21300: 0.712848, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 21350: 0.419574, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 21400: 0.357414, learning rate: 0.029404, 1.676s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 21450: 0.384809, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 21500: 0.761849, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 21550: 0.662588, learning rate: 0.029404, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 21600: 1.160766, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 21650: 0.593137, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 21700: 0.948223, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 21750: 0.517467, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 21800: 0.385687, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 21850: 0.560366, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 21900: 0.676762, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 21950: 0.861858, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 22000: 1.078232, learning rate: 0.029404, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 22050: 0.681907, learning rate: 0.029404, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 22100: 0.560249, learning rate: 0.029404, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 22150: 0.390807, learning rate: 0.029404, 1.681s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 78.2%\n",
      "Random shuffle\n",
      "Minibatch loss at step 22200: 0.954242, learning rate: 0.027933, 1.977s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 22250: 0.506477, learning rate: 0.027933, 1.683s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 22300: 0.427739, learning rate: 0.027933, 1.683s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 22350: 0.408255, learning rate: 0.027933, 1.682s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 22400: 0.530550, learning rate: 0.027933, 1.684s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 22450: 0.434727, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 22500: 0.568615, learning rate: 0.027933, 1.681s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 22550: 1.003657, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 22600: 1.420177, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 22650: 0.696828, learning rate: 0.027933, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 22700: 0.566131, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 22750: 0.640087, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 22800: 0.434582, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 22850: 0.559171, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 22900: 0.495435, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 22950: 0.706752, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 23000: 0.754883, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 23050: 0.438249, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 23100: 0.566940, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 23150: 0.532479, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 23200: 0.501138, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 23250: 0.662778, learning rate: 0.027933, 1.682s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 23300: 0.617635, learning rate: 0.027933, 1.683s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 23350: 0.984416, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 23400: 0.643511, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 23450: 0.642567, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 23500: 0.566932, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 23550: 0.693867, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 23600: 0.609162, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 23650: 1.079753, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 23700: 0.784523, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 23750: 0.686951, learning rate: 0.027933, 1.684s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 23800: 0.726731, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 23850: 0.654173, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 23900: 0.610456, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 23950: 0.610359, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 24000: 1.155863, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 24050: 0.587946, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 24100: 0.546154, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 24150: 0.692918, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 24200: 0.587103, learning rate: 0.027933, 1.676s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 24250: 1.078978, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 24300: 0.380850, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 24350: 1.052939, learning rate: 0.027933, 1.675s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 24400: 0.757324, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 24450: 0.453549, learning rate: 0.027933, 1.676s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 24500: 0.449373, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 24550: 0.767959, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 24600: 0.349979, learning rate: 0.027933, 1.677s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 24650: 0.681228, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 24700: 0.508109, learning rate: 0.027933, 1.674s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 24750: 0.740904, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 24800: 0.819236, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 24850: 0.627740, learning rate: 0.027933, 1.689s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 24900: 1.046428, learning rate: 0.027933, 1.687s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 24950: 0.517245, learning rate: 0.027933, 1.686s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 25000: 0.745818, learning rate: 0.027933, 1.676s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 25050: 0.363470, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 25100: 0.861559, learning rate: 0.027933, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 25150: 0.707288, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 25200: 0.319683, learning rate: 0.027933, 1.675s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 25250: 0.795582, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 25300: 0.734748, learning rate: 0.027933, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 25350: 0.367552, learning rate: 0.027933, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.0%\n",
      "Random shuffle\n",
      "Minibatch loss at step 25400: 0.602562, learning rate: 0.026537, 1.978s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 25450: 0.520563, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 25500: 0.741118, learning rate: 0.026537, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 25550: 0.539928, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 25600: 0.490040, learning rate: 0.026537, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 25650: 0.544046, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 25700: 1.096678, learning rate: 0.026537, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 25750: 0.497713, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 25800: 0.905950, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 25850: 0.657789, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 25900: 1.334981, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 25950: 0.936112, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 26000: 0.572100, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 26050: 0.434152, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 26100: 0.479991, learning rate: 0.026537, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 26150: 0.613087, learning rate: 0.026537, 1.681s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 26200: 1.164321, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 26250: 1.034037, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 26300: 0.405797, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 26350: 0.415067, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 26400: 0.641597, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 26450: 0.532043, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 26500: 0.616908, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 26550: 0.590854, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 26600: 0.982464, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 26650: 1.214607, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 26700: 0.716473, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 26750: 0.838355, learning rate: 0.026537, 1.692s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 26800: 0.533271, learning rate: 0.026537, 1.687s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 26850: 0.705494, learning rate: 0.026537, 1.682s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 26900: 0.791039, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 26950: 0.504752, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 27000: 0.639135, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 27050: 0.430825, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 27100: 0.599921, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 27150: 0.544684, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 27200: 0.477984, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 27250: 0.651832, learning rate: 0.026537, 1.682s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 27300: 0.800645, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 27350: 0.590489, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 27400: 0.445015, learning rate: 0.026537, 1.679s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 27450: 0.810816, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 27500: 0.502104, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 27550: 0.627196, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 27600: 0.649872, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 27650: 0.777438, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 27700: 1.074374, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 27750: 0.568491, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 27800: 0.635369, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 27850: 0.670788, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 27900: 0.574626, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 27950: 0.423511, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 28000: 0.750154, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 28050: 0.751556, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 28100: 0.271422, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 28150: 1.037576, learning rate: 0.026537, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 28200: 0.445561, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 28250: 0.788573, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 28300: 0.424173, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 28350: 0.465079, learning rate: 0.026537, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 28400: 1.016961, learning rate: 0.026537, 1.675s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 28450: 1.301850, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 28500: 0.473032, learning rate: 0.026537, 1.676s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.4%\n",
      "Random shuffle\n",
      "Minibatch loss at step 28550: 0.629890, learning rate: 0.025210, 1.972s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 28600: 0.795306, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 28650: 0.620704, learning rate: 0.025210, 1.694s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 28700: 0.297167, learning rate: 0.025210, 1.684s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 28750: 0.588039, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 28800: 0.530981, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 28850: 0.856405, learning rate: 0.025210, 1.681s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 28900: 0.796005, learning rate: 0.025210, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 28950: 0.591728, learning rate: 0.025210, 1.684s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 29000: 0.619740, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 29050: 0.452944, learning rate: 0.025210, 1.682s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29100: 0.671810, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 29150: 0.770754, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 29200: 0.411411, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29250: 0.565297, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29300: 0.727815, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29350: 1.368916, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29400: 0.561456, learning rate: 0.025210, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 29450: 0.522818, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 29500: 1.018978, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29550: 0.428980, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 29600: 0.680390, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 29650: 0.768270, learning rate: 0.025210, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 29700: 0.584119, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 29750: 0.526130, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29800: 0.518331, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29850: 0.359375, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 29900: 0.344115, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 29950: 0.649082, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 30000: 0.385230, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 30050: 0.665057, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 30100: 0.941337, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 30150: 0.509253, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 30200: 0.426727, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 30250: 0.471442, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 30300: 0.498611, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 30350: 0.394370, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 30400: 0.394593, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 30450: 0.420003, learning rate: 0.025210, 1.681s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 30500: 0.514210, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 30550: 0.711968, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 30600: 0.598504, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 30650: 0.478508, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 30700: 1.151818, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 30750: 0.606331, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 30800: 0.638210, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 30850: 0.777658, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 30900: 0.281470, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 30950: 0.914385, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 31000: 0.576229, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 31050: 0.856230, learning rate: 0.025210, 1.676s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 31100: 0.463923, learning rate: 0.025210, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 31150: 0.450181, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 31200: 0.910598, learning rate: 0.025210, 1.681s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 31250: 0.762033, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 31300: 0.694661, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 31350: 1.003754, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 31400: 0.881133, learning rate: 0.025210, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 31450: 0.779126, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 31500: 0.500667, learning rate: 0.025210, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 31550: 0.359233, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 31600: 0.681912, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 31650: 0.281324, learning rate: 0.025210, 1.677s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 79.6%\n",
      "Random shuffle\n",
      "Minibatch loss at step 31700: 0.499755, learning rate: 0.025210, 1.977s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 31750: 0.421813, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 31800: 0.559517, learning rate: 0.023949, 1.682s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 31850: 0.553724, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 31900: 0.605364, learning rate: 0.023949, 1.683s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 31950: 0.431996, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 32000: 0.711683, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 32050: 0.429954, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 32100: 0.738036, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 32150: 0.604280, learning rate: 0.023949, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 32200: 1.079900, learning rate: 0.023949, 1.683s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 32250: 0.443829, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 32300: 0.820098, learning rate: 0.023949, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 32350: 0.454246, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 32400: 0.415217, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 32450: 0.456708, learning rate: 0.023949, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 32500: 0.581715, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 32550: 0.551412, learning rate: 0.023949, 1.676s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 32600: 0.870995, learning rate: 0.023949, 1.682s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 32650: 0.721792, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 32700: 0.456327, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 32750: 0.309292, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 32800: 0.325638, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 32850: 0.480963, learning rate: 0.023949, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 32900: 0.681385, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 32950: 0.390359, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 33000: 0.586587, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 33050: 0.498099, learning rate: 0.023949, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 33100: 0.720654, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 33150: 0.487759, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 33200: 0.705746, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 33250: 0.700215, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 33300: 0.599429, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 33350: 0.819015, learning rate: 0.023949, 1.675s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 33400: 0.574486, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 33450: 0.597391, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 33500: 0.508424, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 33550: 0.437158, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 33600: 0.615004, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 33650: 0.477544, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 33700: 0.526363, learning rate: 0.023949, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 33750: 0.455563, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 33800: 0.510501, learning rate: 0.023949, 1.676s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 33850: 0.324177, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 33900: 0.770867, learning rate: 0.023949, 1.687s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 33950: 0.530289, learning rate: 0.023949, 1.690s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 34000: 0.439012, learning rate: 0.023949, 1.685s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 34050: 0.538996, learning rate: 0.023949, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 34100: 0.699594, learning rate: 0.023949, 1.682s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 34150: 0.548457, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 34200: 0.354085, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 34250: 0.466996, learning rate: 0.023949, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 34300: 0.512656, learning rate: 0.023949, 1.676s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 34350: 0.773635, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 34400: 0.543071, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 34450: 0.711054, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 34500: 0.603127, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 34550: 0.475782, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 34600: 1.139981, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 34650: 0.400536, learning rate: 0.023949, 1.676s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 34700: 0.579267, learning rate: 0.023949, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 34750: 0.383198, learning rate: 0.023949, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 34800: 0.433395, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 34850: 0.598029, learning rate: 0.023949, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Random shuffle\n",
      "Minibatch loss at step 34900: 0.587028, learning rate: 0.022752, 1.975s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 34950: 0.269013, learning rate: 0.022752, 1.681s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 35000: 0.346382, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 35050: 0.393919, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 35100: 0.659329, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 35150: 0.413305, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 35200: 0.629670, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 35250: 0.577776, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 35300: 0.400257, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 35350: 0.862171, learning rate: 0.022752, 1.681s\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 35400: 0.804835, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 35450: 0.316527, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 35500: 0.446998, learning rate: 0.022752, 1.681s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 35550: 0.374315, learning rate: 0.022752, 1.681s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 35600: 0.277342, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 35650: 0.325660, learning rate: 0.022752, 1.681s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 35700: 0.929205, learning rate: 0.022752, 1.688s\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 35750: 0.373706, learning rate: 0.022752, 1.685s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 35800: 0.530827, learning rate: 0.022752, 1.685s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 35850: 0.668633, learning rate: 0.022752, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 35900: 0.561585, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 35950: 0.356918, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 36000: 0.530675, learning rate: 0.022752, 1.683s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 36050: 0.502573, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 36100: 0.539626, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 36150: 0.350596, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 36200: 0.245865, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 36250: 0.690503, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 36300: 0.472489, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 36350: 0.564512, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 36400: 0.575553, learning rate: 0.022752, 1.681s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 36450: 0.509339, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 36500: 0.653968, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 36550: 0.494440, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 36600: 0.588301, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 36650: 0.379443, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 36700: 0.493609, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 36750: 0.648489, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 36800: 0.428433, learning rate: 0.022752, 1.676s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 36850: 0.539545, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 36900: 0.379453, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 36950: 0.413668, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 37000: 0.443693, learning rate: 0.022752, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 37050: 0.563471, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 37100: 0.976960, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 37150: 0.757903, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 37200: 0.413327, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 37250: 0.391840, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 37300: 0.403681, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 37350: 0.490052, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 37400: 0.496490, learning rate: 0.022752, 1.676s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 37450: 0.688086, learning rate: 0.022752, 1.676s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 37500: 0.498447, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 37550: 0.488321, learning rate: 0.022752, 1.686s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 37600: 0.434926, learning rate: 0.022752, 1.687s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 37650: 0.489630, learning rate: 0.022752, 1.677s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 37700: 0.520118, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 37750: 0.382271, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 37800: 0.400419, learning rate: 0.022752, 1.676s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 37850: 0.541144, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 37900: 0.436463, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 37950: 1.220031, learning rate: 0.022752, 1.679s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 38000: 0.570058, learning rate: 0.022752, 1.678s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.6%\n",
      "Random shuffle\n",
      "Minibatch loss at step 38050: 0.401816, learning rate: 0.021614, 1.978s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 38100: 1.045732, learning rate: 0.021614, 1.681s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 38150: 0.335772, learning rate: 0.021614, 1.682s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 38200: 0.387781, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 38250: 0.368500, learning rate: 0.021614, 1.682s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 38300: 0.718120, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 38350: 0.413782, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 38400: 0.368459, learning rate: 0.021614, 1.685s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 38450: 0.398684, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 38500: 0.306468, learning rate: 0.021614, 1.681s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 38550: 0.490893, learning rate: 0.021614, 1.681s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 38600: 0.299127, learning rate: 0.021614, 1.685s\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 38650: 0.609360, learning rate: 0.021614, 1.683s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 38700: 0.366791, learning rate: 0.021614, 1.681s\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 38750: 0.439616, learning rate: 0.021614, 1.682s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 38800: 0.470949, learning rate: 0.021614, 1.682s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 38850: 0.606338, learning rate: 0.021614, 1.679s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 38900: 0.412679, learning rate: 0.021614, 1.678s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 38950: 0.389302, learning rate: 0.021614, 1.679s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 39000: 0.631603, learning rate: 0.021614, 1.677s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 39050: 0.545765, learning rate: 0.021614, 1.676s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 39100: 0.709015, learning rate: 0.021614, 1.678s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 39150: 0.332839, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 39200: 0.424631, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 39250: 0.359155, learning rate: 0.021614, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 39300: 0.499000, learning rate: 0.021614, 1.679s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 39350: 0.392541, learning rate: 0.021614, 1.690s\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 39400: 0.766504, learning rate: 0.021614, 1.678s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 39450: 0.312301, learning rate: 0.021614, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 39500: 0.461233, learning rate: 0.021614, 1.677s\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 39550: 0.962651, learning rate: 0.021614, 1.681s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 39600: 0.847208, learning rate: 0.021614, 1.678s\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 39650: 0.723890, learning rate: 0.021614, 1.678s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 39700: 0.614168, learning rate: 0.021614, 1.677s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 39750: 0.556911, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 39800: 0.663021, learning rate: 0.021614, 1.679s\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 39850: 0.352435, learning rate: 0.021614, 1.679s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 39900: 0.381994, learning rate: 0.021614, 1.680s\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 39950: 0.489679, learning rate: 0.021614, 1.676s\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 40000: 0.444279, learning rate: 0.021614, 1.676s\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 81.2%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "num_steps = 50001\n",
    "\n",
    "FLAGS.training = True\n",
    "\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "with tf.Session(graph=graph) as session:\n",
    "    if FLAGS.training:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print('Initialized')\n",
    "        offset = 0\n",
    "        for step in range(num_steps):\n",
    "            if(offset == 0):\n",
    "                train_dataset, train_labels = shuffle_in_unison_inplace(train_dataset, train_labels)\n",
    "                print('Random shuffle')\n",
    "            feed_dict = {\n",
    "                tf_train_dataset : train_dataset[offset:(offset + BATCH_SIZE)], \n",
    "                tf_train_labels : train_labels[offset:(offset + BATCH_SIZE)]\n",
    "            }\n",
    "            offset += BATCH_SIZE\n",
    "            if offset+BATCH_SIZE > train_labels.shape[0]:\n",
    "                offset = 0\n",
    "            _, l, lr, train_acc, valid_acc = \\\n",
    "                session.run([optimizer, loss, learning_rate, train_accuracy, valid_accuracy], feed_dict=feed_dict)\n",
    "            if (step % 100 == 0):\n",
    "                elapsed_time = time.time() - start_time\n",
    "                start_time = time.time()\n",
    "                print('Minibatch loss at step %d: %f, learning rate: %.6f, %.3fs' % (step, l, lr, elapsed_time))\n",
    "                train_accuracies.append(train_acc)\n",
    "                print('Minibatch accuracy: %.1f%%' % train_accuracies[-1])\n",
    "                valid_accuracies.append(valid_acc)\n",
    "                print('Validation accuracy: %.1f%%' % valid_accuracies[-1])\n",
    "        saver.save(session, 'multi.ckpt', write_meta_graph=False)\n",
    "    else:\n",
    "        saver.restore(session, 'multi.ckpt')\n",
    "    #predictions = test_prediction.eval()\n",
    "    #print('Test accuracy: %.1f%%' % test_accuracy.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
